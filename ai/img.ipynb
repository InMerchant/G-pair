{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bee6ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목을 입력하세요: 바보\n",
      "몇화인지 입력하세요: 1\n",
      "이미지 파일 이름 변경이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 사용자로부터 제목과 몇화를 입력받기\n",
    "title = input(\"제목을 입력하세요: \")\n",
    "episode = input(\"몇화인지 입력하세요: \")\n",
    "\n",
    "# 이미지 파일의 확장자\n",
    "extension = \".png\"  # 이미지 파일 확장자에 맞게 변경해주세요\n",
    "\n",
    "# 디렉토리 경로 설정\n",
    "directory_path = r\"C:\\Users\\ska0047\\MStudy\\vitImg\"\n",
    "\n",
    "# 디렉토리 내 모든 이미지 파일 찾기\n",
    "image_files = [f for f in os.listdir(directory_path) if f.endswith(extension)]\n",
    "\n",
    "# 이미지 파일을 순차적으로 변경하기\n",
    "for i, image_file in enumerate(image_files, start=1):\n",
    "    new_name = f\"{title}_{episode}_{i}{extension}\"\n",
    "    old_path = os.path.join(directory_path, image_file)\n",
    "    new_path = os.path.join(directory_path, new_name)\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "print(\"이미지 파일 이름 변경이 완료되었습니다.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이미지 넘버링\n",
    "import os\n",
    "\n",
    "# 이미지 파일들이 있는 폴더 경로\n",
    "folder_path = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "\n",
    "# 폴더 내의 모든 파일 목록 가져오기\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# PNG 파일만 골라내기\n",
    "png_files = [file for file in file_list if file.lower().endswith('.png')]\n",
    "\n",
    "# PNG 파일 수 확인\n",
    "num_png_files = len(png_files)\n",
    "\n",
    "# 새로운 파일 이름으로 파일들 이름 변경하기\n",
    "for i, file_name in enumerate(png_files, start=1):\n",
    "    # 번호의 자릿수에 맞게 포맷팅하여 새로운 파일 이름 생성\n",
    "    new_file_name = f'{i:0{len(str(num_png_files))}}.png'\n",
    "    \n",
    "    # 기존 파일을 새로운 이름으로 변경\n",
    "    os.rename(os.path.join(folder_path, file_name), os.path.join(folder_path, new_file_name))\n",
    "print(\"넘버링 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c612701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이미지 처리 중: 100%|█| 5/5 [01:38<00:00, 19.62s/i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 캡션 생성 및 CSV 파일 저장 완료.\n",
      "번역이 완료되었습니다.\n",
      "지정한 단어들을 포함한 텍스트를 삭제한 후 새로운 CSV 파일로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "#2. 이미지 캡션 생성 후 번역 후 정제\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Blip 모델과 프로세서 불러오기\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "# 이미지가 있는 디렉토리와 CSV 파일을 저장할 디렉토리 경로 설정\n",
    "image_dir = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "csv_dir = r'C:\\Users\\ska0047\\MStudy\\vitCsv'\n",
    "csv_filename = '상황.csv'\n",
    "\n",
    "# 이미지 파일 목록 가져오기\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')]\n",
    "total_images = len(image_files)\n",
    "\n",
    "# CSV 파일 생성 및 헤더 추가\n",
    "csv_path = os.path.join(csv_dir, csv_filename)\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['파일이름', '이미지캡션'])\n",
    "\n",
    "# 진행 상황 로딩 바 설정 (폭을 절반으로 줄임)\n",
    "with tqdm(total=total_images, desc=\"이미지 처리 중\", ncols=50) as pbar:\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # 이미지 열기\n",
    "        raw_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 이미지 캡션 생성\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        # CSV 파일에 결과 추가\n",
    "        with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow([filename, caption])\n",
    "\n",
    "        # 진행 상황 업데이트\n",
    "        pbar.update(1)\n",
    "\n",
    "# 작업 완료 메시지 표시\n",
    "print(\"이미지 캡션 생성 및 CSV 파일 저장 완료.\")\n",
    "import csv\n",
    "from googletrans import Translator\n",
    "\n",
    "# 구글 번역기 초기화\n",
    "translator = Translator()\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "# 번역 함수\n",
    "def translate_text(text, target_lang):\n",
    "    try:\n",
    "        translation = translator.translate(text, dest=target_lang)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"번역 중 오류 발생: {e}\")\n",
    "        return \"번역 실패\"\n",
    "\n",
    "# CSV 파일 열기 및 번역\n",
    "translated_data = []\n",
    "\n",
    "with open(input_csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        if len(row) == 2:  # CSV 파일의 각 행은 두 개의 열로 구성되어야 합니다\n",
    "            image_name, english_sentence = row[0], row[1]\n",
    "            translated_sentence = translate_text(english_sentence, 'ko')\n",
    "            translated_data.append([image_name, translated_sentence])\n",
    "\n",
    "# 번역된 내용을 CSV 파일에 저장\n",
    "translated_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "with open(translated_csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(translated_data)\n",
    "\n",
    "if translated_data:\n",
    "    print(\"번역이 완료되었습니다.\")\n",
    "else:\n",
    "    print(\"번역된 내용이 없습니다.\")\n",
    "    \n",
    "import csv\n",
    "\n",
    "# 기존 CSV 파일 경로 및 새로 저장할 CSV 파일 경로\n",
    "csv_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "new_csv_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\정제된상황.csv'\n",
    "\n",
    "# 삭제할 단어들 리스트로 지정\n",
    "delete_words = [\"그림\", \"만화\", \"클로즈업\", \"애니메이션\", \"이미지\", \"아라페드\", \"캐릭터\", \"포스터\", ]  # 삭제할 단어들을 여기에 추가\n",
    "\n",
    "# CSV 파일 읽기 및 특정 단어 삭제 후 새로운 CSV 파일로 저장\n",
    "with open(csv_path, 'r', newline='', encoding='utf-8') as infile, open(new_csv_path, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    csv_reader = csv.reader(infile)\n",
    "    csv_writer = csv.writer(outfile)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # 여러 단어를 한 번에 삭제하기 위해 반복문 사용\n",
    "        cleaned_row = []\n",
    "        for cell in row:\n",
    "            if isinstance(cell, str):\n",
    "                # 특정 단어들을 포함하는 경우 삭제 후 새로운 행으로 작성\n",
    "                for word in delete_words:\n",
    "                    cell = cell.replace(word, '')\n",
    "            cleaned_row.append(cell)\n",
    "        csv_writer.writerow(cleaned_row)\n",
    "\n",
    "print(f'지정한 단어들을 포함한 텍스트를 삭제한 후 새로운 CSV 파일로 저장했습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "904c7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "OCR Progress: 100%|█| 92/92 [03:33<00:00,  2.33s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR 처리 및 CSV 파일 저장 완료\n",
      "두 개의 CSV 파일이 합쳐졌습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#3. OCR대사 추출과 이미지캡션과 대사 csv병합\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import easyocr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 폴더 내 이미지 파일 목록 얻기\n",
    "image_folder = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
    "\n",
    "# 정규 표현식 패턴 설정\n",
    "pattern = re.compile(r'[^A-Za-z0-9가-힣\\s]')\n",
    "\n",
    "# easyocr 리더 초기화\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
    "\n",
    "# 결과를 저장할 CSV 파일 열기\n",
    "csv_file = open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\대사.csv', 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"OCR Progress\", ncols=50):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    results = reader.readtext(image_path, detail=0)\n",
    "\n",
    "    if results:\n",
    "        output_text = ' '.join(results)\n",
    "\n",
    "        # 기호나 특수 문자 제거\n",
    "        cleaned_text = pattern.sub('', output_text)\n",
    "        cleaned_text_with_slash = cleaned_text\n",
    "        csv_writer.writerow([cleaned_text_with_slash])  # 파일 이름 대신 출력 문장 저장\n",
    "    else:\n",
    "        csv_writer.writerow(['None'])  # 결과가 없을 때 'None' 저장\n",
    "\n",
    "# CSV 파일 닫기\n",
    "csv_file.close()\n",
    "print(\"OCR 처리 및 CSV 파일 저장 완료\")\n",
    "# 상황대사 파일병합\n",
    "import csv\n",
    "\n",
    "# 첫 번째 CSV 파일 읽기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\정제된상황.csv', 'r', newline='', encoding='utf-8') as csv_file1:\n",
    "    csv_reader1 = csv.reader(csv_file1)\n",
    "    data1 = list(csv_reader1)\n",
    "\n",
    "# 두 번째 CSV 파일 읽기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\대사.csv', 'r', newline='', encoding='utf-8') as csv_file2:\n",
    "    csv_reader2 = csv.reader(csv_file2)\n",
    "    data2 = list(csv_reader2)\n",
    "\n",
    "# 새로운 CSV 파일 생성 및 쓰기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황과 대사.csv', 'w', newline='', encoding='utf-8') as merged_csv_file:\n",
    "    csv_writer = csv.writer(merged_csv_file)\n",
    "\n",
    "    # 데이터 병합하여 쓰기\n",
    "    for row1, row2 in zip(data1, data2):\n",
    "        file_name = row1[0]\n",
    "        sentence1 = row1[1]\n",
    "        sentence2 = row2[0]\n",
    "        csv_writer.writerow([file_name, sentence1, sentence2])\n",
    "\n",
    "print(\"두 개의 CSV 파일이 합쳐졌습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "44e2eb70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                      | 0/91 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# tqdm을 사용하여 진행 상황을 로딩바로 표시\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)), ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     new_df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m문장1의 분류 라벨링\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     new_df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m문장2의 분류 라벨링\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m classify_sentence(df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     54\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[143], line 13\u001b[0m, in \u001b[0;36mclassify_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     11\u001b[0m config \u001b[38;5;241m=\u001b[39m BertConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification(config)\n\u001b[1;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m     16\u001b[0m     sentence,\n\u001b[0;32m     17\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[0;32m   1015\u001b[0m                      map_location,\n\u001b[0;32m   1016\u001b[0m                      pickle_module,\n\u001b[0;32m   1017\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1018\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py:1357\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1357\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#4. 윤리검증\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    model_path = \"epoch_4_evalAcc_64.pth\"\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    config = BertConfig.from_pretrained('bert-base-multilingual-cased', num_labels=8)\n",
    "    model = BertForSequenceClassification(config)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')), strict=False)\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# csv 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사.csv', header=None)\n",
    "\n",
    "# 새로운 데이터프레임 생성\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# 파일 이름, 문장1, 문장2, 문장1의 분류 라벨링, 문장2의 분류 라벨링으로 구성\n",
    "new_df['파일 이름'] = df[0]\n",
    "new_df['문장1'] = df[1]\n",
    "new_df['문장2'] = df[2]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# tqdm을 사용하여 진행 상황을 로딩바로 표시\n",
    "for i in tqdm(range(len(df)), ncols=50):\n",
    "    new_df.loc[i, '문장1의 분류 라벨링'] = classify_sentence(df.loc[i, 1])\n",
    "    new_df.loc[i, '문장2의 분류 라벨링'] = classify_sentence(df.loc[i, 2])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# 새로운 csv 파일로 저장\n",
    "new_df.to_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv', index=False)\n",
    "\n",
    "\n",
    "# 파일 읽기\n",
    "df = pd.read_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv')\n",
    "\n",
    "# '.0'을 제거하고 숫자로 변환한 후 다시 문자열로 변환\n",
    "df['문장1의 분류 라벨링'] = df['문장1의 분류 라벨링'].astype(float).astype('Int64').astype(str)\n",
    "df['문장2의 분류 라벨링'] = df['문장2의 분류 라벨링'].astype(float).astype('Int64').astype(str)\n",
    "\n",
    "# 결과를 새로운 파일에 저장\n",
    "df.to_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv', index=False)\n",
    "\n",
    "print(f\"경과 시간: {end - start}초\")\n",
    "    #\"['CENSURE'비난]\": 0,\n",
    "    #\"['HATE'차별]\": 1,\n",
    "    #\"['DISCRIMINATION'혐오]\": 2,\n",
    "    #\"['SEXUAL'선정]\": 3,\n",
    "    #\"['ABUSE'욕설]\": 4,\n",
    "    #\"['VIOLENCE'폭력]\": 5,\n",
    "    #\"['CRIME'범죄]\": 6,\n",
    "    #\"['IMMORAL_NONE']\": 7,\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구이미지 캡션과 번역\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "\n",
    "# 이미지 폴더 경로 설정\n",
    "image_folder = r\"C:\\Users\\ska0047\\MStudy\\vitImg\"\n",
    "output_csv = r\"C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv\"\n",
    "\n",
    "# 이미지 파일 목록 가져오기\n",
    "image_files = [os.path.join(image_folder, filename) for filename in os.listdir(image_folder) if filename.endswith('.png')]\n",
    "\n",
    "# 결과를 저장할 CSV 파일 열기 또는 생성\n",
    "file_exists = os.path.exists(output_csv)\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = [\"Image\", \"Caption\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    # 이미지 파일을 순회하며 캡션 생성 및 저장\n",
    "    for image_path in tqdm(image_files, desc=\"Generating captions\", ncols=100):\n",
    "        images = [Image.open(image_path)]\n",
    "        if images[0].mode != \"RGB\":\n",
    "            images[0] = images[0].convert(mode=\"RGB\")\n",
    "\n",
    "        pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(device)\n",
    "\n",
    "        output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "        captions = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        if captions:\n",
    "            writer.writerow({\"Image\": os.path.basename(image_path), \"Caption\": captions[0]})\n",
    "\n",
    "print(\"이미지 캡션 생성 및 CSV 파일에 저장 완료\")\n",
    "\n",
    "import csv\n",
    "from googletrans import Translator\n",
    "\n",
    "# 구글 번역기 초기화\n",
    "translator = Translator()\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "# 번역 함수\n",
    "def translate_text(text, target_lang):\n",
    "    try:\n",
    "        translation = translator.translate(text, dest=target_lang)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"번역 중 오류 발생: {e}\")\n",
    "        return \"번역 실패\"\n",
    "\n",
    "# CSV 파일 열기 및 번역\n",
    "translated_data = []\n",
    "\n",
    "with open(input_csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        if len(row) == 2:  # CSV 파일의 각 행은 두 개의 열로 구성되어야 합니다\n",
    "            image_name, english_sentence = row[0], row[1]\n",
    "            translated_sentence = translate_text(english_sentence, 'ko')\n",
    "            translated_data.append([image_name, translated_sentence])\n",
    "\n",
    "# 번역된 내용을 CSV 파일에 저장\n",
    "translated_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "with open(translated_csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(translated_data)\n",
    "\n",
    "if translated_data:\n",
    "    print(\"번역이 완료되었습니다.\")\n",
    "else:\n",
    "    print(\"번역된 내용이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4bdd7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "넘버링 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이미지 처리 중:   0%|      | 0/50 [00:00<?, ?it/s]C:\\Users\\ska0047\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "이미지 처리 중: 100%|█| 50/50 [21:12<00:00, 25.45s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 캡션 생성 및 CSV 파일 저장 완료.\n",
      "번역이 완료되었습니다.\n",
      "지정한 단어들을 포함한 텍스트를 삭제한 후 새로운 CSV 파일로 저장했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "OCR Progress: 100%|█| 50/50 [06:48<00:00,  8.17s/i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR 처리 및 CSV 파일 저장 완료\n",
      "두 개의 CSV 파일이 합쳐졌습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 50/50 [11:40<00:00, 14.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경과 시간: 700.8384759426117초\n"
     ]
    }
   ],
   "source": [
    "# 1. 이미지 넘버링\n",
    "import os\n",
    "\n",
    "# 이미지 파일들이 있는 폴더 경로\n",
    "folder_path = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "\n",
    "# 폴더 내의 모든 파일 목록 가져오기\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# PNG 파일만 골라내기\n",
    "png_files = [file for file in file_list if file.lower().endswith('.png')]\n",
    "\n",
    "# PNG 파일 수 확인\n",
    "num_png_files = len(png_files)\n",
    "\n",
    "# 새로운 파일 이름으로 파일들 이름 변경하기\n",
    "for i, file_name in enumerate(png_files, start=1):\n",
    "    # 번호의 자릿수에 맞게 포맷팅하여 새로운 파일 이름 생성\n",
    "    new_file_name = f'{i:0{len(str(num_png_files))}}.png'\n",
    "    \n",
    "    # 기존 파일을 새로운 이름으로 변경\n",
    "    os.rename(os.path.join(folder_path, file_name), os.path.join(folder_path, new_file_name))\n",
    "print(\"넘버링 완료\")\n",
    "#2. 이미지 캡션 생성 후 번역 후 정제\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Blip 모델과 프로세서 불러오기\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "# 이미지가 있는 디렉토리와 CSV 파일을 저장할 디렉토리 경로 설정\n",
    "image_dir = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "csv_dir = r'C:\\Users\\ska0047\\MStudy\\vitCsv'\n",
    "csv_filename = '상황.csv'\n",
    "\n",
    "# 이미지 파일 목록 가져오기\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png')]\n",
    "total_images = len(image_files)\n",
    "\n",
    "# CSV 파일 생성 및 헤더 추가\n",
    "csv_path = os.path.join(csv_dir, csv_filename)\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    #csv_writer.writerow(['파일이름', '이미지캡션'])\n",
    "\n",
    "# 진행 상황 로딩 바 설정 (폭을 절반으로 줄임)\n",
    "with tqdm(total=total_images, desc=\"이미지 처리 중\", ncols=50) as pbar:\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # 이미지 열기\n",
    "        raw_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 이미지 캡션 생성\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        # CSV 파일에 결과 추가\n",
    "        with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow([filename, caption])\n",
    "\n",
    "        # 진행 상황 업데이트\n",
    "        pbar.update(1)\n",
    "\n",
    "# 작업 완료 메시지 표시\n",
    "print(\"이미지 캡션 생성 및 CSV 파일 저장 완료.\")\n",
    "import csv\n",
    "from googletrans import Translator\n",
    "\n",
    "# 구글 번역기 초기화\n",
    "translator = Translator()\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "# 번역 함수\n",
    "def translate_text(text, target_lang):\n",
    "    try:\n",
    "        translation = translator.translate(text, dest=target_lang)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"번역 중 오류 발생: {e}\")\n",
    "        return \"번역 실패\"\n",
    "\n",
    "# CSV 파일 열기 및 번역\n",
    "translated_data = []\n",
    "\n",
    "with open(input_csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        if len(row) == 2:  # CSV 파일의 각 행은 두 개의 열로 구성되어야 합니다\n",
    "            image_name, english_sentence = row[0], row[1]\n",
    "            translated_sentence = translate_text(english_sentence, 'ko')\n",
    "            translated_data.append([image_name, translated_sentence])\n",
    "\n",
    "# 번역된 내용을 CSV 파일에 저장\n",
    "translated_csv_file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "\n",
    "with open(translated_csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(translated_data)\n",
    "\n",
    "if translated_data:\n",
    "    print(\"번역이 완료되었습니다.\")\n",
    "else:\n",
    "    print(\"번역된 내용이 없습니다.\")\n",
    "    \n",
    "import csv\n",
    "\n",
    "# 기존 CSV 파일 경로 및 새로 저장할 CSV 파일 경로\n",
    "csv_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황.csv'\n",
    "new_csv_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\정제된상황.csv'\n",
    "\n",
    "# 삭제할 단어들 리스트로 지정\n",
    "delete_words = [\"그림\", \"만화\", \"클로즈업\", \"애니메이션\", \"이미지\", \"아라페드\", \"캐릭터\", \"포스터\", ]  # 삭제할 단어들을 여기에 추가\n",
    "\n",
    "# CSV 파일 읽기 및 특정 단어 삭제 후 새로운 CSV 파일로 저장\n",
    "with open(csv_path, 'r', newline='', encoding='utf-8') as infile, open(new_csv_path, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    csv_reader = csv.reader(infile)\n",
    "    csv_writer = csv.writer(outfile)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # 여러 단어를 한 번에 삭제하기 위해 반복문 사용\n",
    "        cleaned_row = []\n",
    "        for cell in row:\n",
    "            if isinstance(cell, str):\n",
    "                # 특정 단어들을 포함하는 경우 삭제 후 새로운 행으로 작성\n",
    "                for word in delete_words:\n",
    "                    cell = cell.replace(word, '')\n",
    "            cleaned_row.append(cell)\n",
    "        csv_writer.writerow(cleaned_row)\n",
    "\n",
    "print(f'지정한 단어들을 포함한 텍스트를 삭제한 후 새로운 CSV 파일로 저장했습니다.')\n",
    "#3. OCR대사 추출과 이미지캡션과 대사 csv병합\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import easyocr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 폴더 내 이미지 파일 목록 얻기\n",
    "image_folder = r'C:\\Users\\ska0047\\MStudy\\vitImg'\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
    "\n",
    "# 정규 표현식 패턴 설정\n",
    "pattern = re.compile(r'[^A-Za-z0-9가-힣\\s]')\n",
    "\n",
    "# easyocr 리더 초기화\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=False)\n",
    "\n",
    "# 결과를 저장할 CSV 파일 열기\n",
    "csv_file = open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\대사.csv', 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"OCR Progress\", ncols=50):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    results = reader.readtext(image_path, detail=0)\n",
    "\n",
    "    if results:\n",
    "        output_text = ' '.join(results)\n",
    "\n",
    "        # 기호나 특수 문자 제거\n",
    "        cleaned_text = pattern.sub('', output_text)\n",
    "        cleaned_text_with_slash = cleaned_text\n",
    "        csv_writer.writerow([cleaned_text_with_slash])  # 파일 이름 대신 출력 문장 저장\n",
    "    else:\n",
    "        csv_writer.writerow(['None'])  # 결과가 없을 때 'None' 저장\n",
    "\n",
    "# CSV 파일 닫기\n",
    "csv_file.close()\n",
    "print(\"OCR 처리 및 CSV 파일 저장 완료\")\n",
    "#상황대사 파일 변환\n",
    "import csv\n",
    "\n",
    "# 첫 번째 CSV 파일 읽기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\정제된상황.csv', 'r', newline='', encoding='utf-8') as csv_file1:\n",
    "    csv_reader1 = csv.reader(csv_file1)\n",
    "    data1 = list(csv_reader1)\n",
    "\n",
    "# 두 번째 CSV 파일 읽기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\대사.csv', 'r', newline='', encoding='utf-8') as csv_file2:\n",
    "    csv_reader2 = csv.reader(csv_file2)\n",
    "    data2 = list(csv_reader2)\n",
    "\n",
    "# 새로운 CSV 파일 생성 및 쓰기\n",
    "with open(r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황과 대사.csv', 'w', newline='', encoding='utf-8') as merged_csv_file:\n",
    "    csv_writer = csv.writer(merged_csv_file)\n",
    "\n",
    "    # 데이터 병합하여 쓰기\n",
    "    for row1, row2 in zip(data1, data2):\n",
    "        file_name = row1[0]\n",
    "        sentence1 = row1[1]\n",
    "        sentence2 = row2[0]\n",
    "        csv_writer.writerow([file_name, sentence1, sentence2])\n",
    "\n",
    "print(\"두 개의 CSV 파일이 합쳐졌습니다.\")\n",
    "# 빈칸채우기\n",
    "import csv\n",
    "\n",
    "# CSV 파일 열기\n",
    "file_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\상황과 대사.csv'\n",
    "with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    data = list(reader)\n",
    "\n",
    "# 빈 값을 빈 문자열('')로 채우기\n",
    "for row in data:\n",
    "    for i, value in enumerate(row):\n",
    "        if not value:\n",
    "            row[i] = 'None'\n",
    "\n",
    "# 기존 파일 덮어쓰기\n",
    "with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)\n",
    "\n",
    "#4. 윤리검증\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    model_path = \"epoch_4_evalAcc_64.pth\"\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    config = BertConfig.from_pretrained('bert-base-multilingual-cased', num_labels=8)\n",
    "    model = BertForSequenceClassification(config)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')), strict=False)\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# csv 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사.csv', header=None)\n",
    "\n",
    "# 새로운 데이터프레임 생성\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# 파일 이름, 문장1, 문장2, 문장1의 분류 라벨링, 문장2의 분류 라벨링으로 구성\n",
    "new_df['파일 이름'] = df[0]\n",
    "new_df['문장1'] = df[1]\n",
    "new_df['문장2'] = df[2]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# tqdm을 사용하여 진행 상황을 로딩바로 표시\n",
    "for i in tqdm(range(len(df)), ncols=50):\n",
    "    new_df.loc[i, '문장1의 분류 라벨링'] = classify_sentence(df.loc[i, 1])\n",
    "    new_df.loc[i, '문장2의 분류 라벨링'] = classify_sentence(df.loc[i, 2])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# 새로운 csv 파일로 저장\n",
    "new_df.to_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv', index=False)\n",
    "\n",
    "\n",
    "# 파일 읽기\n",
    "df = pd.read_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv')\n",
    "\n",
    "# '.0'을 제거하고 숫자로 변환한 후 다시 문자열로 변환\n",
    "df['문장1의 분류 라벨링'] = df['문장1의 분류 라벨링'].astype(float).astype('Int64').astype(str)\n",
    "df['문장2의 분류 라벨링'] = df['문장2의 분류 라벨링'].astype(float).astype('Int64').astype(str)\n",
    "\n",
    "# 결과를 새로운 파일에 저장\n",
    "df.to_csv('C:\\\\Users\\\\ska0047\\\\MStudy\\\\vitCsv\\\\상황과 대사_윤리검증.csv', index=False)\n",
    "\n",
    "print(f\"경과 시간: {end - start}초\")\n",
    "    #\"['CENSURE'비난]\": 0,\n",
    "    #\"['HATE'차별]\": 1,\n",
    "    #\"['DISCRIMINATION'혐오]\": 2,\n",
    "    #\"['SEXUAL'선정]\": 3,\n",
    "    #\"['ABUSE'욕설]\": 4,\n",
    "    #\"['VIOLENCE'폭력]\": 5,\n",
    "    #\"['CRIME'범죄]\": 6,\n",
    "    #\"['IMMORAL_NONE']\": 7,\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d78aded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 이미지 파일이 들어있는 폴더 경로\n",
    "folder_path = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\더미'\n",
    "\n",
    "# 폴더 내 모든 파일 목록 가져오기\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 이미지 파일만 골라내기\n",
    "image_files = [f for f in file_list if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "# 이미지 파일을 순서대로 정렬\n",
    "image_files.sort()\n",
    "\n",
    "# 이미지 파일을 10개씩 묶기\n",
    "batch_size = 10\n",
    "batches = [image_files[i:i + batch_size] for i in range(0, len(image_files), batch_size)]\n",
    "\n",
    "# 이미지 이름 변경\n",
    "for i, batch in enumerate(batches, start=1):\n",
    "    for j, filename in enumerate(batch, start=1):\n",
    "        new_name = f\"{i} ({j}){os.path.splitext(filename)[1]}\"  # 새로운 파일 이름 설정\n",
    "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_name))  # 파일 이름 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "654e1d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 데이터를 C:\\Users\\ska0047\\MStudy\\vitCsv\\프리드로우\\상황과 대사_윤리검증.json으로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_and_save(csv_file, json_file):\n",
    "    data = []\n",
    "    \n",
    "    # CSV 파일 읽기\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    # JSON 형식으로 변환\n",
    "    json_data = json.dumps(data, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    with open(json_file, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(json_data)\n",
    "\n",
    "# CSV 파일 경로와 저장할 JSON 파일 경로\n",
    "csv_filename = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\프리드로우\\상황과 대사_윤리검증.csv'\n",
    "json_filename = r'C:\\Users\\ska0047\\MStudy\\vitCsv\\프리드로우\\상황과 대사_윤리검증.json'\n",
    "\n",
    "# CSV를 JSON으로 변환하고 JSON 파일로 저장\n",
    "csv_to_json_and_save(csv_filename, json_filename)\n",
    "print(f'변환된 데이터를 {json_filename}으로 저장했습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d79fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
